{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIE/UbV8w/Kl9DABjOv0EN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uarmirimau/PIAIC-ISB-Batch58-Projects-/blob/master/RAG_Project_2_with_pdf_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G1aBMx4FvtZ4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install faiss-cpu\n",
        "!pip install google-generativeai\n",
        "!pip install tiktoken\n",
        "!pip install langchain_google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "CG1sYHvix0KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sPm8B6fH0fB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pypdf import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os"
      ],
      "metadata": {
        "id": "rIIEI2fqyQEa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fg2OijcIcxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "Y08F_jxqdHvS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Replace 'my_document.pdf' with the actual name of your PDF file\n",
        "pdf_path = \"my_document.pdf\"\n",
        "\n",
        "def load_pdf(file_path):\n",
        "    \"\"\"Loads a PDF file.\"\"\"\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = loader.load_and_split()\n",
        "    return pages\n",
        "\n",
        "# Call the function to load the PDF\n",
        "loaded_docs = load_pdf(pdf_path)\n",
        "\n",
        "# Print some info to verify\n",
        "print(f\"Loaded {len(loaded_docs)} pages from your PDF.\")\n",
        "print(\"First 100 words of the first page:\")\n",
        "print(loaded_docs[0].page_content[:100])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XH6Bwebu6Qbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(loaded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X5NkwNoPZRsi",
        "outputId": "2cd8c5a0-e93d-494a-94e2-b5f2a97c26cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(loaded_docs)"
      ],
      "metadata": {
        "id": "a_O8UyDCZdl5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGZPS3bJZsWJ",
        "outputId": "977305fb-88b5-464b-b174-0cf5874b7b90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[77]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaJIGVByZ6Lg",
        "outputId": "d8296612-7f64-4689-a81f-f9e9c6497b86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'my_document.pdf', 'page': 34}, page_content='“It’s\\tnot\\tfor\\tyou”\\nWe’re\\tnot\\tsupposed\\tto\\tsay\\tthat.\\tWe’re\\tcertainly\\tnot\\tsupposed\\tto\\twant\\tto\\tsay\\tthat.\\nBut\\twe\\tmust.\\n“It’s\\tnot\\tfor\\tyou”\\tshows\\tthe\\tability\\tto\\trespect\\tsomeone\\tenough\\tthat\\tyou’re\\tnot\\ngoing\\tto\\twaste\\ttheir\\ttime,\\tpander\\tto\\tthem,\\tor\\tinsist\\tthat\\tthey\\tchange\\ttheir\\tbeliefs.')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "E74GccRjfMpf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # Import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model= \"models/embedding-001\")\n",
        "vector = embeddings.embed_query(\"hello, world\")\n",
        "vector[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTw99ELZgpQ4",
        "outputId": "90e8c4de-7f02-4319-8bf7-d0840ccae80c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.053597815334796906,\n",
              " -0.030782219022512436,\n",
              " -0.03252851590514183,\n",
              " -0.02810630202293396,\n",
              " 0.022345904260873795]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "Dn16d4nngxqM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import search\n",
        "retriver = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "retrived_docs = retriver.invoke(\"give me two line of summary of my shared pdf\")\n",
        "print(retrived_docs[2].page_content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mcgokoTplLfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash-exp\", temperature=0.3, max_token = 500)"
      ],
      "metadata": {
        "id": "bbX52rLermep"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def ask_question(retriever, question): # add the retriever variable\n",
        "  \"\"\"Asks a question and gets an answer using the vector store and Gemini.\"\"\"\n",
        "  llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash-exp\", temperature=0.3, max_token = 500)\n",
        "  qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever) # pass retriever to the chain\n",
        "  answer = qa_chain.invoke(question)\n",
        "  return answer\n",
        "\n",
        "\n",
        "# Ask your question here!\n",
        "my_question = \"What is the topic of this document?\"\n",
        "\n",
        "# Get the Answer from the document\n",
        "answer = ask_question(retriever=retriver, question=my_question) # Call the function with the retriever\n",
        "\n",
        "print(f\"Question: {my_question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlE-WvoAvIFk",
        "outputId": "a5646f59-681a-4e51-dee2-42e3148b83f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the topic of this document?\n",
            "Answer: {'query': 'What is the topic of this document?', 'result': 'Based on the provided table of contents and index, this document appears to be about marketing.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "YNScHxM-bKHR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# Import ChatPromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate # Importing the ChatPromptTemplate class\n",
        "\n",
        "system_prompt = (\n",
        "    \"you are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer the question. \"\n",
        "    \"If you don't know the answer, just say that you don't know. \"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"{input}\")\n",
        "    ]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "HeowTdRbbnHY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain # Importing the necessary function\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriver, question_answer_chain)\n"
      ],
      "metadata": {
        "id": "n7s4iTI4duhP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\" : \"what is The\tCanvas\tof\tDreams\tand\tDesires\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-7DcaHngZKq",
        "outputId": "e93a4753-a44a-43a2-b743-b445dcece015"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Canvas of Dreams and Desires is the title of Chapter Seven. It discusses how marketers, like artists, don't need many colors to paint an original masterpiece. It also discusses the core basket of dreams and desires that people have, such as security, sex, strength, sympathy, and tension. The chapter emphasizes that marketers should begin with dreams and fears, emotional states, and the change they seek to make, rather than with their machines, inventory, or tactics.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}